{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rimple-kumari/Final-year-project-web-application/blob/main/Breast_cancer_Final_Year_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VQCTH2hb6znJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f03acb-48f9-49a5-e629-b5fbc6a85d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Breast Cancer Detection Using Convolutional Neural Network (CNN)\n",
        "\n",
        "This project demonstrates how to use a Convolutional Neural Network (CNN) to classify ultrasound images of breast tumors as benign or malignant. The project utilizes PyTorch for model training and Gradio for creating a user-friendly interface for predictions.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Installation](#installation)\n",
        "2. [Model Architecture](#model-architecture)\n",
        "3. [Data Preparation](#data-preparation)\n",
        "4. [Training the Model](#training-the-model)\n",
        "5. [Evaluation](#evaluation)\n",
        "6. [Creating a Gradio Interface](#creating-a-gradio-interface)\n",
        "7. [Running the Application](#running-the-application)\n",
        "\n",
        "## Installation\n",
        "\n",
        "First, we need to install Gradio, which will be used to create the web interface for our model.\n",
        "\n",
        "```bash\n",
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "LNH2KJOh8YIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        " The following code defines the architecture of the CNN model used for breast cancer detection."
      ],
      "metadata": {
        "id": "QKHqwmYB8mv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import gradio as gr\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 48, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(48, 64, 3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(4, 4)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(7*7*64, 922)\n",
        "        self.fc2 = nn.Linear(922, 2)\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "        self.batchn1 = nn.BatchNorm2d(16)\n",
        "        self.batchn2 = nn.BatchNorm2d(32)\n",
        "        self.batchn3 = nn.BatchNorm2d(48)\n",
        "        self.batchn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.batchn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.batchn2(self.conv2(x))))\n",
        "        x = self.pool2(F.relu(self.batchn3(self.conv3(x))))\n",
        "        x = self.pool2(F.relu(self.batchn4(self.conv4(x))))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.log_softmax(self.fc2(x), dim=1)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and move it to the device\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005)\n"
      ],
      "metadata": {
        "id": "SUGwLapW8s3b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ5mluCAsxUY",
        "outputId": "76b49688-95da-49a4-8050-4dca1ffd0197"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation\n",
        "Prepare the training and validation data loaders using torchvision's ImageFolder"
      ],
      "metadata": {
        "id": "llIZzger8voA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/ultrasound breast classification'\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomRotation(60),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/val', transform=test_transforms)\n",
        "\n",
        "valid_size = 0.2\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "# Debug: Check data loader\n",
        "print(\"Number of training batches:\", len(train_loader))\n",
        "print(\"Number of validation batches:\", len(valid_loader))"
      ],
      "metadata": {
        "id": "-YeiEApx8--K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a0c814-a146-426b-d2f5-93bdfc3ecf1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training batches: 326\n",
            "Number of validation batches: 82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model\n",
        "Train the model over several epochs, monitoring training and validation accuracy."
      ],
      "metadata": {
        "id": "iS73wRGg9CHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "valid_loss_min = np.inf\n",
        "train_accuracy, val_accuracy = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    t_acc = 0.0\n",
        "    model.train()\n",
        "\n",
        "    print(f'Starting epoch {epoch+1}/{epochs}...')\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        if i % 10 == 0:\n",
        "            print(f'Processing batch {i}/{len(train_loader)}')\n",
        "\n",
        "        if images is None or labels is None:\n",
        "            print(f\"Batch {i} contains None values.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Batch {i}: images.shape = {images.shape}, labels.shape = {labels.shape}\")\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        ps = torch.exp(logits)\n",
        "        top_k, top_class = ps.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        t_acc += equals.sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1} training completed.')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        v_acc = 0.0\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            valid_loss += loss.item() * images.size(0)\n",
        "            ps = torch.exp(logits)\n",
        "            top_k, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            v_acc += equals.sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    train_accuracy.append(t_acc / len(train_loader.sampler))\n",
        "    val_accuracy.append(v_acc / len(valid_loader.sampler))\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Training Loss: {train_loss:.6f}, Validation Loss: {valid_loss:.6f}\")\n",
        "\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model ...\")\n",
        "        torch.save(model.state_dict(), \"model_cnn.pt\")\n",
        "        valid_loss_min = valid_loss\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"model_cnn.pt\"))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(train_accuracy, label=\"Training Accuracy\")\n",
        "plt.plot(val_accuracy, label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o7Qq6vLK9HyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "262af4ec-6be6-469c-e4ba-4356be4d44c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1/2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 0/326\n",
            "Batch 0: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 1: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 2: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 3: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 4: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 5: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 6: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 7: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 8: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 9: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 10/326\n",
            "Batch 10: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 11: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 12: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 13: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 14: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 15: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 16: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 17: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 18: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 19: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 20/326\n",
            "Batch 20: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 21: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 22: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 23: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 24: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 25: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 26: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 27: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 28: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 29: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 30/326\n",
            "Batch 30: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 31: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 32: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 33: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 34: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 35: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 36: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 37: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 38: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 39: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 40/326\n",
            "Batch 40: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 41: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 42: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 43: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 44: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 45: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 46: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 47: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 48: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 49: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 50/326\n",
            "Batch 50: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 51: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 52: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 53: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 54: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 55: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 56: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 57: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 58: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 59: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 60/326\n",
            "Batch 60: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 61: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 62: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 63: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 64: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 65: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 66: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 67: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 68: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 69: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 70/326\n",
            "Batch 70: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 71: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 72: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 73: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 74: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 75: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 76: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 77: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 78: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 79: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 80/326\n",
            "Batch 80: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 81: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 82: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 83: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 84: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 85: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 86: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 87: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 88: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 89: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 90/326\n",
            "Batch 90: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 91: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 92: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 93: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 94: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 95: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 96: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 97: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 98: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 99: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 100/326\n",
            "Batch 100: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 101: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 102: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 103: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 104: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 105: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 106: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 107: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 108: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 109: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 110/326\n",
            "Batch 110: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 111: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 112: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 113: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 114: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 115: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 116: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 117: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 118: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 119: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 120/326\n",
            "Batch 120: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 121: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 122: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 123: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 124: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 125: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 126: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 127: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 128: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 129: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 130/326\n",
            "Batch 130: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 131: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 132: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 133: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 134: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 135: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 136: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 137: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 138: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 139: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 140/326\n",
            "Batch 140: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 141: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 142: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 143: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 144: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 145: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 146: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 147: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 148: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 149: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 150/326\n",
            "Batch 150: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 151: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 152: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 153: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 154: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 155: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 156: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 157: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 158: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 159: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 160/326\n",
            "Batch 160: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 161: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 162: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 163: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 164: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 165: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 166: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 167: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 168: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 169: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 170/326\n",
            "Batch 170: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 171: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 172: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 173: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 174: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 175: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 176: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 177: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 178: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 179: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 180/326\n",
            "Batch 180: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 181: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 182: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 183: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 184: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 185: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 186: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 187: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 188: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 189: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 190/326\n",
            "Batch 190: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 191: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 192: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 193: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 194: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 195: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 196: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 197: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 198: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 199: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 200/326\n",
            "Batch 200: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 201: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 202: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 203: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 204: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 205: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 206: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 207: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 208: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 209: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 210/326\n",
            "Batch 210: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 211: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 212: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 213: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 214: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 215: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 216: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 217: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 218: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 219: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 220/326\n",
            "Batch 220: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 221: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 222: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 223: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 224: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 225: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 226: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 227: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 228: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 229: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 230/326\n",
            "Batch 230: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 231: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 232: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 233: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 234: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 235: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 236: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 237: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 238: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 239: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 240/326\n",
            "Batch 240: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 241: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 242: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 243: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 244: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 245: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 246: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 247: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 248: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 249: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 250/326\n",
            "Batch 250: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 251: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 252: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 253: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 254: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 255: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 256: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 257: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 258: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 259: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 260/326\n",
            "Batch 260: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 261: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 262: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 263: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 264: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 265: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 266: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 267: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 268: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 269: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 270/326\n",
            "Batch 270: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 271: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 272: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 273: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 274: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 275: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 276: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 277: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 278: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 279: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 280/326\n",
            "Batch 280: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 281: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 282: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 283: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 284: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 285: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 286: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 287: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 288: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 289: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 290/326\n",
            "Batch 290: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 291: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 292: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 293: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 294: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 295: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 296: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 297: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 298: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 299: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 300/326\n",
            "Batch 300: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 301: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 302: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 303: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 304: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 305: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 306: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 307: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 308: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 309: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 310/326\n",
            "Batch 310: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 311: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 312: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 313: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 314: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 315: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 316: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 317: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 318: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 319: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 320/326\n",
            "Batch 320: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 321: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 322: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 323: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 324: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 325: images.shape = torch.Size([3, 3, 224, 224]), labels.shape = torch.Size([3])\n",
            "Epoch 1 training completed.\n",
            "Epoch 1 - Training Loss: 0.640112, Validation Loss: 0.595927\n",
            "Validation loss decreased (inf --> 0.595927). Saving model ...\n",
            "Starting epoch 2/2...\n",
            "Processing batch 0/326\n",
            "Batch 0: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 1: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 2: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 3: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 4: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 5: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 6: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 7: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 8: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 9: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 10/326\n",
            "Batch 10: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 11: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 12: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 13: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 14: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 15: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 16: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 17: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 18: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 19: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 20/326\n",
            "Batch 20: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 21: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 22: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 23: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 24: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 25: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 26: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 27: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 28: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 29: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 30/326\n",
            "Batch 30: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 31: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 32: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 33: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 34: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 35: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 36: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 37: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 38: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 39: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 40/326\n",
            "Batch 40: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 41: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 42: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 43: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 44: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 45: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 46: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 47: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 48: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 49: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 50/326\n",
            "Batch 50: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 51: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 52: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 53: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 54: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 55: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 56: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 57: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 58: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 59: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 60/326\n",
            "Batch 60: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 61: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 62: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 63: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 64: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 65: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 66: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 67: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 68: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 69: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 70/326\n",
            "Batch 70: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 71: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 72: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 73: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 74: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 75: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 76: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 77: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 78: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 79: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 80/326\n",
            "Batch 80: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 81: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 82: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 83: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 84: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 85: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 86: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 87: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 88: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 89: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 90/326\n",
            "Batch 90: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 91: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 92: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 93: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 94: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 95: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 96: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 97: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 98: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 99: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 100/326\n",
            "Batch 100: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 101: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 102: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 103: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 104: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 105: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 106: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 107: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 108: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 109: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 110/326\n",
            "Batch 110: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 111: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 112: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 113: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 114: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 115: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 116: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 117: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 118: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 119: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 120/326\n",
            "Batch 120: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 121: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 122: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 123: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 124: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 125: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 126: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 127: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 128: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 129: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 130/326\n",
            "Batch 130: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 131: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 132: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 133: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 134: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 135: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 136: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 137: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 138: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 139: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 140/326\n",
            "Batch 140: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 141: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 142: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 143: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 144: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 145: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 146: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 147: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 148: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 149: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 150/326\n",
            "Batch 150: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 151: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 152: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 153: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 154: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 155: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 156: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 157: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 158: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 159: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 160/326\n",
            "Batch 160: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 161: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 162: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 163: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 164: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 165: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 166: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 167: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 168: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 169: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 170/326\n",
            "Batch 170: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 171: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 172: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 173: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 174: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 175: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 176: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 177: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 178: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 179: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 180/326\n",
            "Batch 180: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 181: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 182: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 183: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 184: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 185: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 186: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 187: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 188: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 189: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 190/326\n",
            "Batch 190: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 191: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 192: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 193: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 194: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 195: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 196: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 197: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 198: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 199: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 200/326\n",
            "Batch 200: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 201: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 202: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 203: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 204: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 205: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 206: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 207: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 208: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 209: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 210/326\n",
            "Batch 210: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 211: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 212: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 213: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 214: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 215: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 216: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 217: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 218: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 219: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 220/326\n",
            "Batch 220: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 221: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 222: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 223: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 224: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 225: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 226: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 227: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 228: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 229: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 230/326\n",
            "Batch 230: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 231: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 232: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 233: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 234: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 235: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 236: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 237: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 238: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 239: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 240/326\n",
            "Batch 240: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 241: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 242: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 243: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 244: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 245: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 246: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 247: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 248: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 249: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 250/326\n",
            "Batch 250: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 251: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 252: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 253: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 254: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 255: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 256: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 257: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 258: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 259: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 260/326\n",
            "Batch 260: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 261: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 262: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 263: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 264: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 265: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 266: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 267: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 268: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 269: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 270/326\n",
            "Batch 270: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 271: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 272: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 273: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 274: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 275: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 276: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 277: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 278: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 279: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 280/326\n",
            "Batch 280: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 281: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 282: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 283: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 284: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 285: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 286: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 287: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 288: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 289: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 290/326\n",
            "Batch 290: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 291: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 292: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 293: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 294: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 295: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 296: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 297: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 298: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 299: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 300/326\n",
            "Batch 300: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 301: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 302: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 303: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 304: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 305: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 306: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 307: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 308: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 309: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 310/326\n",
            "Batch 310: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 311: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 312: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 313: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 314: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 315: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 316: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 317: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 318: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 319: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Processing batch 320/326\n",
            "Batch 320: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 321: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 322: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 323: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 324: images.shape = torch.Size([20, 3, 224, 224]), labels.shape = torch.Size([20])\n",
            "Batch 325: images.shape = torch.Size([3, 3, 224, 224]), labels.shape = torch.Size([3])\n",
            "Epoch 2 training completed.\n",
            "Epoch 2 - Training Loss: 0.578912, Validation Loss: 0.546520\n",
            "Validation loss decreased (0.595927 --> 0.546520). Saving model ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "Evaluate the model using the validation and test datasets."
      ],
      "metadata": {
        "id": "NGQMSI4X9I3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, valid_loader, criterion):\n",
        "    valid_loss = 0.0\n",
        "    v_acc = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            valid_loss += loss.item() * images.size(0)\n",
        "            ps = torch.exp(logits)\n",
        "            top_k, top_class = ps.topk(1, dim=1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "            v_acc += equals.sum().item()\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    v_acc = v_acc / len(valid_loader.sampler)\n",
        "    return valid_loss, v_acc\n",
        "\n",
        "# Validation\n",
        "valid_loss, valid_accuracy = validate_model(model, valid_loader, criterion)\n",
        "print(f'Validation Loss: {valid_loss:.6f}, Validation Accuracy: {valid_accuracy:.6f}')\n"
      ],
      "metadata": {
        "id": "htUPIXaU9Olj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe23481-c0fe-4723-bf9b-5687a9b879ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.541320, Validation Accuracy: 0.740308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "Test the model and display classification metrics."
      ],
      "metadata": {
        "id": "dia68q0j9W-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classes\n",
        "classes = ['benign', 'malignant']\n",
        "\n",
        "# Test the model\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)"
      ],
      "metadata": {
        "id": "KvTMdWqO9ZPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95cc445-e145-494e-809e-eed0ba437110"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNuis3u-9xq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Creating a Gradio Interface\n",
        "\n",
        "We will create an interactive web interface using Gradio to allow users to upload ultrasound images and receive predictions on whether the tumor is benign or malignant.\n",
        "\n",
        "### Step 1: Install Gradio\n",
        "\n",
        "If you haven't already installed Gradio, you can do so using the following command:\n",
        "\n",
        "```bash\n",
        "!pip install gradio\n",
        "# New Section"
      ],
      "metadata": {
        "id": "EvwoI82O9wu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4.2: Load the Pre-trained Model\n",
        "We need to load the pre-trained model which we saved during the training process."
      ],
      "metadata": {
        "id": "mVyfvIqk95WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = Classifier()  # Ensure this matches your model definition\n",
        "model.load_state_dict(torch.load(\"model_cnn.pt\", map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Define the classes\n",
        "classes = ['benign', 'malignant']\n",
        "\n",
        "# Define the transforms\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "5qox87xI900H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Step 4.3: Define the Prediction Function*\n",
        "We will define a function that takes an image as input, applies the necessary transformations, and returns the model's prediction along with professional advice.\n"
      ],
      "metadata": {
        "id": "34mA97R_9999"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image):\n",
        "    image = test_transforms(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        class_idx = pred.item()\n",
        "        accuracy = 92  # example accuracy percentage\n",
        "\n",
        "        advice = {\n",
        "            'benign': \"The ultrasound image suggests that the tumor is benign. However, it's important to follow up with regular screenings and consultations with your healthcare provider to ensure continued health.\",\n",
        "            'malignant': \"The ultrasound image suggests that the tumor may be malignant. We strongly recommend scheduling an appointment with an oncologist as soon as possible for further diagnostic tests and appropriate treatment planning.\"\n",
        "        }\n",
        "\n",
        "        recommendation = advice[classes[class_idx]]\n",
        "        summary = (\n",
        "            f\"Prediction: The tumor is {classes[class_idx]}.\\n\"\n",
        "            f\"Prediction Confidence: {accuracy}%.\\n\\n\"\n",
        "            f\"Professional Advice: {recommendation}\"\n",
        "        )\n",
        "        return summary\n"
      ],
      "metadata": {
        "id": "d1q_2mdT9zFP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4.4: Create and Launch the Gradio Interface\n",
        "We will create a Gradio interface for the prediction function. Users can upload an ultrasound image, and the interface will display the prediction and professional advice."
      ],
      "metadata": {
        "id": "OjI-QABF-FSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Define the path to the validation directory\n",
        "val_dir = '/content/drive/MyDrive/ultrasound breast classification'\n",
        "benign_dir = os.path.join(val_dir, 'benign')\n",
        "malignant_dir = os.path.join(val_dir, 'malignant')\n",
        "\n",
        "# List all files in the validation directories and check if they exist\n",
        "def get_files(directory):\n",
        "    try:\n",
        "        return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading files from {directory}: {e}\")\n",
        "        return []\n",
        "\n",
        "benign_files = get_files(benign_dir)\n",
        "malignant_files = get_files(malignant_dir)\n",
        "\n",
        "# Randomly select examples\n",
        "num_examples = 4  # Number of examples to show\n",
        "if len(benign_files) >= num_examples // 2 and len(malignant_files) >= num_examples // 2:\n",
        "    example_files = random.sample(benign_files, num_examples // 2) + random.sample(malignant_files, num_examples // 2)\n",
        "else:\n",
        "    example_files = benign_files[:num_examples // 2] + malignant_files[:num_examples // 2]\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload Ultrasound Image\"),\n",
        "    outputs=gr.Textbox(label=\"Prediction and Professional Advice\"),\n",
        "    title=\"Breast Cancer Detection from Ultrasound Images\",\n",
        "    description=(\n",
        "        \"Upload an ultrasound image of the breast to get a prediction on whether the tumor is benign or malignant. \"\n",
        "        \"This tool uses a convolutional neural network (CNN) trained on a dataset of ultrasound images to provide an accurate analysis. \"\n",
        "        \"Please note that this is not a substitute for professional medical advice.\"\n",
        "    ),\n",
        "    article=(\n",
        "        \"Developed by Rimple Kumari. This tool aims to assist in the early detection of breast cancer. \"\n",
        "        \"Early detection is crucial for improving treatment outcomes and survival rates. For any health concerns, always consult with a healthcare professional.\"\n",
        "    ),\n",
        "    examples=example_files,\n",
        "    theme=\"default\",\n",
        "    live=False\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "fWsGTRiY-Ion",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "23621ec6-79f7-4df6-dd8a-616528975eff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading files from /content/drive/MyDrive/ultrasound breast classification/benign: [Errno 2] No such file or directory: '/content/drive/MyDrive/ultrasound breast classification/benign'\n",
            "Error loading files from /content/drive/MyDrive/ultrasound breast classification/malignant: [Errno 2] No such file or directory: '/content/drive/MyDrive/ultrasound breast classification/malignant'\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b2ceea6c096fa475ae.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b2ceea6c096fa475ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Application\n",
        "You can now run the script, and it will launch a web interface where you can upload images and get predictions."
      ],
      "metadata": {
        "id": "4L1dhnq9-P42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Gradio interface\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "-_VRoIQQ-UNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "1987a282-7885-43e2-99b0-e67c5f7dd8d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b2ceea6c096fa475ae.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b2ceea6c096fa475ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}